{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"generate_legs.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOOf6ghtvZ/KM/y9j5pPz0K"},"kernelspec":{"name":"python3","display_name":"Python 3.8.5 64-bit ('torch1_py38': conda)","metadata":{"interpreter":{"hash":"b50600eb1b324defb81823d73056f274d476f3491b23fb736d624cff6e98896d"}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hNrKmsAK_MsQ","executionInfo":{"status":"ok","timestamp":1611735107885,"user_tz":-540,"elapsed":28209,"user":{"displayName":"Yoshihiro Sakatani","photoUrl":"https://lh3.googleusercontent.com/-XT8ndXbkfI8/AAAAAAAAAAI/AAAAAAAABVk/Upi1N41fw1M/s64/photo.jpg","userId":"03638891422887413039"}},"outputId":"1cd2895e-fac3-4b8d-f222-6c10cdb3e020"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=False)\n","cwd = '/content/drive/MyDrive/BookingcomChallenge2021/'\n","\n","import os\n","os.chdir(cwd)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"L-gYRZDD_TbL","executionInfo":{"status":"ok","timestamp":1611735211224,"user_tz":-540,"elapsed":1440,"user":{"displayName":"Yoshihiro Sakatani","photoUrl":"https://lh3.googleusercontent.com/-XT8ndXbkfI8/AAAAAAAAAAI/AAAAAAAABVk/Upi1N41fw1M/s64/photo.jpg","userId":"03638891422887413039"}}},"source":["import argparse\n","import torch\n","import legdata as data\n","from tqdm import tqdm"],"execution_count":67,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xw7SUMv8_iSu","executionInfo":{"status":"ok","timestamp":1611735112581,"user_tz":-540,"elapsed":11747,"user":{"displayName":"Yoshihiro Sakatani","photoUrl":"https://lh3.googleusercontent.com/-XT8ndXbkfI8/AAAAAAAAAAI/AAAAAAAABVk/Upi1N41fw1M/s64/photo.jpg","userId":"03638891422887413039"}},"outputId":"f34f0900-ddeb-4235-e4c0-d2ea29ff3df7"},"source":["parser = argparse.ArgumentParser(description='PyTorch Wikitext-2 Language Model')\r\n","\r\n","# Model parameters.\r\n","parser.add_argument('--data', type=str, default='./data/wikitext-2',\r\n","                    help='location of the data corpus')\r\n","parser.add_argument('--checkpoint', type=str, default='./model.pt',\r\n","                    help='model checkpoint to use')\r\n","parser.add_argument('--outf', type=str, default='generated.txt',\r\n","                    help='output file for generated text')\r\n","parser.add_argument('--words', type=int, default='1000',\r\n","                    help='number of words to generate')\r\n","parser.add_argument('--bptt', type=int, default=35,\r\n","                    help='sequence length')\r\n","parser.add_argument('--seed', type=int, default=None,\r\n","                    help='random seed')\r\n","parser.add_argument('--cuda', action='store_true',\r\n","                    help='use CUDA')\r\n","parser.add_argument('--temperature', type=float, default=1.0,\r\n","                    help='temperature - higher will increase diversity')\r\n","parser.add_argument('--log-interval', type=int, default=100,\r\n","                    help='reporting interval')"],"execution_count":68,"outputs":[{"output_type":"execute_result","data":{"text/plain":["_StoreAction(option_strings=['--log-interval'], dest='log_interval', nargs=None, const=None, default=100, type=<class 'int'>, choices=None, help='reporting interval', metavar=None)"]},"metadata":{},"execution_count":68}]},{"cell_type":"code","metadata":{"id":"ljH7eKB8_tj7","executionInfo":{"status":"ok","timestamp":1611735136807,"user_tz":-540,"elapsed":770,"user":{"displayName":"Yoshihiro Sakatani","photoUrl":"https://lh3.googleusercontent.com/-XT8ndXbkfI8/AAAAAAAAAAI/AAAAAAAABVk/Upi1N41fw1M/s64/photo.jpg","userId":"03638891422887413039"}}},"source":["args = parser.parse_args(args=[\"--data\", \"../booking_com_data/legs_4legs\",\\\n","                               \"--checkpoint\", \"../models/lstm_transformer.pth\",\\\n","                               \"--outf\", \"../result/generated_by_lstm_transformer.txt\",\\\n","                               \"--words\", \"1\",\\\n","                               \"--bptt\", \"4\",\\\n","                               \"--temperature\", \"1.0\",\\\n","                               \"--cuda\"])"],"execution_count":97,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mpGne3OiAQ3M","executionInfo":{"status":"ok","timestamp":1611735150919,"user_tz":-540,"elapsed":1284,"user":{"displayName":"Yoshihiro Sakatani","photoUrl":"https://lh3.googleusercontent.com/-XT8ndXbkfI8/AAAAAAAAAAI/AAAAAAAABVk/Upi1N41fw1M/s64/photo.jpg","userId":"03638891422887413039"}},"outputId":"6d2f8400-1b62-4359-b576-dc53ca34e3aa"},"source":["# Set the random seed manually for reproducibility.\r\n","if args.seed:\r\n","    torch.manual_seed(args.seed)\r\n","\r\n","if torch.cuda.is_available():\r\n","    if not args.cuda:\r\n","        print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\r\n","\r\n","device = torch.device(\"cuda\" if args.cuda else \"cpu\")\r\n","device"],"execution_count":98,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cpu')"]},"metadata":{},"execution_count":98}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0qA55xIYAV87","executionInfo":{"status":"ok","timestamp":1611735176542,"user_tz":-540,"elapsed":12430,"user":{"displayName":"Yoshihiro Sakatani","photoUrl":"https://lh3.googleusercontent.com/-XT8ndXbkfI8/AAAAAAAAAAI/AAAAAAAABVk/Upi1N41fw1M/s64/photo.jpg","userId":"03638891422887413039"}},"outputId":"2a033f9b-553d-469e-a4eb-3e23077ce189"},"source":["if args.temperature < 1e-3:\n","    parser.error(\"--temperature has to be greater or equal 1e-3\")\n","\n","with open(args.checkpoint, 'rb') as f:\n","    model = torch.load(f, map_location='cpu').to(device)\n","model.eval()"],"execution_count":99,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RNNModel(\n","  (drop): Dropout(p=0.1, inplace=False)\n","  (encoder): Embedding(39878, 512)\n","  (rnn): GRU(512, 1024, num_layers=3, dropout=0.1)\n","  (decoder): Linear(in_features=1024, out_features=39878, bias=True)\n",")"]},"metadata":{},"execution_count":99}]},{"cell_type":"code","metadata":{"id":"h5Q_8A0PAaII","executionInfo":{"status":"ok","timestamp":1611735229015,"user_tz":-540,"elapsed":8991,"user":{"displayName":"Yoshihiro Sakatani","photoUrl":"https://lh3.googleusercontent.com/-XT8ndXbkfI8/AAAAAAAAAAI/AAAAAAAABVk/Upi1N41fw1M/s64/photo.jpg","userId":"03638891422887413039"}}},"source":["corpus = data.Corpus(args.data)\r\n","ntokens = len(corpus.dictionary)\r\n","\r\n","model_type = model.model_type if hasattr(model, 'model_type') else None"],"execution_count":100,"outputs":[]},{"cell_type":"code","execution_count":101,"metadata":{},"outputs":[],"source":["test_data = corpus.test.view(-1, 4)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"63ukkJ12Avst","executionInfo":{"status":"ok","timestamp":1611735286587,"user_tz":-540,"elapsed":10104,"user":{"displayName":"Yoshihiro Sakatani","photoUrl":"https://lh3.googleusercontent.com/-XT8ndXbkfI8/AAAAAAAAAAI/AAAAAAAABVk/Upi1N41fw1M/s64/photo.jpg","userId":"03638891422887413039"}},"outputId":"a5796dcb-046e-40bf-ec4c-9a26052d1c38"},"source":["n_correct = 0\n","\n","if model_type == 'LSTMTransformer':\n","    hidden = model.init_hidden(1)\n","    mems = None\n","elif model_type == 'Transformer':\n","    pass\n","else:\n","    hidden = model.init_hidden(1)\n","\n","with open(args.outf, 'w') as outf:\n","    with torch.no_grad():  # no tracking history\n","        for i, q in enumerate(tqdm(test_data)):\n","            input = q[:-1].view(-1, 1)\n","            if model_type == \"LSTMTransformer\":\n","                output, _, _ = model(input, hidden, mems)\n","            elif model_type == 'Transformer':\n","                output = model(input, False)\n","            else:\n","                output, _ = model(input, hidden)\n","            word_weights = output[-1].squeeze().div(args.temperature).exp().cpu()\n","            word_indices = torch.argsort(word_weights, descending=True)[:4]\n","            if q[-1] in word_indices:\n","                n_correct += 1"],"execution_count":104,"outputs":[{"output_type":"error","ename":"IndentationError","evalue":"expected an indented block (<ipython-input-104-f152cec4eb27>, line 20)","traceback":["\u001b[1;36m  File \u001b[1;32m\"<ipython-input-104-f152cec4eb27>\"\u001b[1;36m, line \u001b[1;32m20\u001b[0m\n\u001b[1;33m    output, _ = model(input, hidden)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"]}]},{"cell_type":"code","execution_count":96,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.03783731219915398"]},"metadata":{},"execution_count":96}],"source":["n_correct/len(test_data)"]}]}